{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Project - Data Cleaning\n",
    "In this notebook, I will do data cleaning and integration for US Weekly Unemployment Initial Claims dataset, US stock price dataset, US gasoline and diesel retail dataset, COVID-19 mobility trends dataset, and COVID-19 cases dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First thing to do: importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing all the datasets that we want to process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the COVID-19 mobility trends dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso, country, date, grocery_and_pharmacy_percent_change_from_baseline, parks_percent_change_from_baseline, residential_percent_change_from_baseline, retail_and_recreation_percent_change_from_baseline, transit_stations_percent_change_from_baseline, workplaces_percent_change_from_baseline, confirmed_cases, confirmed_deaths, gov_response_stringency_index, total_tests, total_vaccinations, people_vaccinated, people_fully_vaccinated, gdp_ppp_per_capita, population, population_density, human_development_index, pop_age_above_65_percentage, health_index\n",
      "AE, United Arab Emirates, 2020-02-15, 4.0, 5.0, 1.0, 0.0, 0.0, 2.0, 8, 0, 0.028, , , , , 75075.26, 9865845.0, 118.0, 0.866, 1.09, 0.886\n",
      "AE, United Arab Emirates, 2020-02-16, 4.0, 4.0, 1.0, 1.0, 1.0, 2.0, 9, 0, 0.028, 5042, , , , 75075.26, 9865845.0, 118.0, 0.866, 1.09, 0.886\n",
      "AE, United Arab Emirates, 2020-02-17, 1.0, 5.0, 1.0, -1.0, 1.0, 2.0, 9, 0, 0.028, , , , , 75075.26, 9865845.0, 118.0, 0.866, 1.09, 0.886\n",
      "AE, United Arab Emirates, 2020-02-18, 1.0, 5.0, 1.0, -2.0, 0.0, 2.0, 9, 0, 0.028, 6693, , , , 75075.26, 9865845.0, 118.0, 0.866, 1.09, 0.886\n",
      "AE, United Arab Emirates, 2020-02-19, 0.0, 4.0, 1.0, -2.0, -1.0, 2.0, 9, 0, 0.028, , , , , 75075.26, 9865845.0, 118.0, 0.866, 1.09, 0.886\n",
      "AE, United Arab Emirates, 2020-02-20, 1.0, 6.0, 1.0, -2.0, 1.0, 1.0, 9, 0, 0.028, , , , , 75075.26, 9865845.0, 118.0, 0.866, 1.09, 0.886\n",
      "AE, United Arab Emirates, 2020-02-21, 2.0, 6.0, 1.0, -3.0, 0.0, -1.0, 11, 0, 0.028, 8894, , , , 75075.26, 9865845.0, 118.0, 0.866, 1.09, 0.886\n",
      "AE, United Arab Emirates, 2020-02-22, 2.0, 4.0, 1.0, -2.0, -2.0, 3.0, 13, 0, 0.028, 12990, , , , 75075.26, 9865845.0, 118.0, 0.866, 1.09, 0.886\n",
      "AE, United Arab Emirates, 2020-02-23, 3.0, 3.0, 1.0, -1.0, -1.0, 4.0, 13, 0, 0.028, , , , , 75075.26, 9865845.0, 118.0, 0.866, 1.09, 0.886\n",
      "AE, United Arab Emirates, 2020-02-24, 0.0, 5.0, 1.0, -3.0, -1.0, 3.0, 13, 0, 0.083, , , , , 75075.26, 9865845.0, 118.0, 0.866, 1.09, 0.886\n"
     ]
    }
   ],
   "source": [
    "mobilityfile = open('COVID-19.csv', newline='')\n",
    "reader_mobility = csv.reader(mobilityfile, delimiter=',')\n",
    "count = 0\n",
    "for row in reader_mobility:\n",
    "    if count > 10:\n",
    "        break\n",
    "    count = count + 1\n",
    "    print(', '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Weekly Unemployment Initial Claims dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE, Adjusted Date, Initial Claims\n",
      "1/7/1967, 1/6/1967, 208000\n",
      "1/14/1967, 1/13/1967, 207000\n",
      "1/21/1967, 1/20/1967, 217000\n",
      "1/28/1967, 1/27/1967, 204000\n",
      "2/4/1967, 2/3/1967, 216000\n",
      "2/11/1967, 2/10/1967, 229000\n",
      "2/18/1967, 2/17/1967, 229000\n",
      "2/25/1967, 2/24/1967, 242000\n",
      "3/4/1967, 3/3/1967, 310000\n",
      "3/11/1967, 3/10/1967, 241000\n"
     ]
    }
   ],
   "source": [
    "unemploymentfile = open('weekly unemployment initial claim.csv', newline='')\n",
    "reader_unemployment = csv.reader(unemploymentfile, delimiter=',')\n",
    "count = 0\n",
    "for row in reader_unemployment:\n",
    "    if count > 10:\n",
    "        break\n",
    "    count = count + 1\n",
    "    print(', '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the U.S. Gasoline and Diesel Retail Prices dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date, A1, A2, A3, R1, R2, R3, M1, M2, M3, P1, P2, P3, D1\n",
      "01/02/1995, 1.127, 1.104, 1.231, 1.079, 1.063, 1.167, 1.17, 1.159, 1.298, 1.272, 1.25, 1.386, 1.104\n",
      "01/09/1995, 1.134, 1.111, 1.232, 1.086, 1.07, 1.169, 1.177, 1.164, 1.3, 1.279, 1.256, 1.387, 1.102\n",
      "01/16/1995, 1.126, 1.102, 1.231, 1.078, 1.062, 1.169, 1.168, 1.155, 1.299, 1.271, 1.249, 1.385, 1.1\n",
      "01/23/1995, 1.132, 1.11, 1.226, 1.083, 1.068, 1.165, 1.177, 1.165, 1.296, 1.277, 1.256, 1.378, 1.095\n",
      "01/30/1995, 1.131, 1.109, 1.221, 1.083, 1.068, 1.162, 1.176, 1.163, 1.291, 1.275, 1.255, 1.37, 1.09\n",
      "02/06/1995, 1.124, 1.103, 1.218, 1.076, 1.062, 1.159, 1.169, 1.157, 1.288, 1.27, 1.25, 1.368, 1.086\n",
      "02/13/1995, 1.121, 1.099, 1.218, 1.074, 1.058, 1.158, 1.166, 1.153, 1.285, 1.265, 1.243, 1.367, 1.088\n",
      "02/20/1995, 1.115, 1.093, 1.213, 1.067, 1.052, 1.153, 1.16, 1.148, 1.28, 1.259, 1.239, 1.363, 1.088\n",
      "02/27/1995, 1.121, 1.101, 1.211, 1.073, 1.06, 1.152, 1.164, 1.153, 1.276, 1.265, 1.246, 1.362, 1.089\n",
      "03/06/1995, 1.123, 1.103, 1.209, 1.076, 1.063, 1.149, 1.167, 1.157, 1.275, 1.263, 1.244, 1.358, 1.089\n"
     ]
    }
   ],
   "source": [
    "gasolinefile = open('PET_PRI_GND_DCUS_NUS_W.csv', newline='')\n",
    "reader_gasoline = csv.reader(gasolinefile, delimiter=',')\n",
    "count = 0\n",
    "for row in reader_gasoline:\n",
    "    if count > 10:\n",
    "        break\n",
    "    count = count + 1\n",
    "    print(', '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the U.S. Covid-19 Cases dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date, cases, deaths\n",
      "2020-01-21, 1, 0\n",
      "2020-01-22, 1, 0\n",
      "2020-01-23, 1, 0\n",
      "2020-01-24, 2, 0\n",
      "2020-01-25, 3, 0\n",
      "2020-01-26, 5, 0\n",
      "2020-01-27, 5, 0\n",
      "2020-01-28, 5, 0\n",
      "2020-01-29, 5, 0\n",
      "2020-01-30, 6, 0\n"
     ]
    }
   ],
   "source": [
    "casefile = open('us.csv', newline='')\n",
    "reader_case = csv.reader(casefile, delimiter=',')\n",
    "count = 0\n",
    "for row in reader_case:\n",
    "    if count > 10:\n",
    "        break\n",
    "    count = count + 1\n",
    "    print(', '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dow Jones Industrial Average Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date, Open, High, Low, Close*, Adj Close**, Volume\n",
      "Mar 26, 2021, 32,681.07, 33,098.83, 32,681.07, 33,072.88, 33,072.88, 383,452,285\n",
      "Mar 22, 2021, 32,601.82, 33,098.83, 32,071.41, 33,072.88, 33,072.88, 19,628,900\n",
      "Mar 15, 2021, 32,798.84, 33,227.78, 32,505.07, 32,627.97, 32,627.97, 23,680,200\n",
      "Mar 08, 2021, 31,512.15, 32,793.32, 31,512.15, 32,778.64, 32,778.64, 21,112,000\n",
      "Mar 01, 2021, 31,065.90, 31,668.34, 30,547.53, 31,496.30, 31,496.30, 21,722,600\n",
      "Feb 22, 2021, 31,381.12, 32,009.64, 30,911.37, 30,932.37, 30,932.37, 22,441,300\n",
      "Feb 15, 2021, 31,472.08, 31,647.53, 31,285.32, 31,494.32, 31,494.32, 13,517,800\n",
      "Feb 08, 2021, 31,191.20, 31,543.82, 31,191.20, 31,458.40, 31,458.40, 15,003,200\n",
      "Feb 01, 2021, 30,054.73, 31,252.18, 30,014.97, 31,148.24, 31,148.24, 16,176,900\n",
      "Jan 25, 2021, 30,989.85, 31,121.42, 29,856.30, 29,982.62, 29,982.62, 24,139,700\n"
     ]
    }
   ],
   "source": [
    "djifile = open('dowjones.csv', newline='')\n",
    "reader_dji = csv.reader(djifile, delimiter=',')\n",
    "count = 0\n",
    "for row in reader_dji:\n",
    "    if count > 10:\n",
    "        break\n",
    "    count = count + 1\n",
    "    print(', '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Do necessary data cleaning and integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first build index for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_idx_string = \"iso, country, date, grocery_and_pharmacy_percent_change_from_baseline, parks_percent_change_from_baseline, residential_percent_change_from_baseline, retail_and_recreation_percent_change_from_baseline, transit_stations_percent_change_from_baseline, workplaces_percent_change_from_baseline, confirmed_cases, confirmed_deaths, gov_response_stringency_index, total_tests, total_vaccinations, people_vaccinated, people_fully_vaccinated, gdp_ppp_per_capita, population, population_density, human_development_index, pop_age_above_65_percentage, health_index\"\n",
    "mobility_idx = mobility_idx_string.split(\", \")\n",
    "unemployment_idx_string = \"DATE, Adjusted Date, Initial Claims\"\n",
    "unemployment_idx = unemployment_idx_string.split(\", \")\n",
    "gasoline_idx_string = \"Date, A1, A2, A3, R1, R2, R3, M1, M2, M3, P1, P2, P3, D1\"\n",
    "gasoline_idx = gasoline_idx_string.split(\", \")\n",
    "case_idx_string = \"date, cases, deaths\"\n",
    "case_idx = case_idx_string.split(\", \")\n",
    "dji_idx_string = \"Date, Open, High, Low, Close*, Adj Close**, Volume\"\n",
    "dji_idx = dji_idx_string.split(\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to initialize a dictionary to contain all the processed data.The key will be the start date of a week, since our data will be in weekly format. The value will be a list containing all the column values.\n",
    "\n",
    "Since for different dataset, the time scope is different, we are taking the intersection of every dataset, which is 2020-02-17 ~ 2021-01-24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataset = {}\n",
    "cur_date = date(2020, 2, 17)\n",
    "while cur_date <= date(2021, 1, 24):\n",
    "    result_dataset[cur_date] = []\n",
    "    cur_date = cur_date + timedelta(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By printing the datasets, we can easily find that the date-time format for different datasets are different. Some are using yyyy-mm-dd, some are using mm/dd/yyyy, while some are using English for month. We would like to convert to a certain format, in this case, yyyy-mm-dd, when processing each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID-19 Cases Dataset\n",
    "We would like to include both case increase and total case up till that time, in a weekly manner. For case increase, we need to remember the case for last week, and compute the difference based on the data for current week and last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_week_start = None\n",
    "store_base_case = 0\n",
    "casefile.seek(0)\n",
    "for row in reader_case:\n",
    "    if row[0] == 'date':\n",
    "        continue\n",
    "    day_info = row[case_idx.index('date')]\n",
    "    day_info = day_info.split('-')\n",
    "    cur_date = date(int(day_info[0]), int(day_info[1]), int(day_info[2]))\n",
    "    if cur_date < date(2020, 2, 17) or cur_date > date(2021, 1, 25):\n",
    "        continue\n",
    "    cur_week_start = cur_date - timedelta(cur_date.weekday())\n",
    "    if store_week_start == None:\n",
    "        store_week_start = cur_week_start\n",
    "        store_base_case = int(row[case_idx.index('cases')])\n",
    "    if cur_week_start != store_week_start:\n",
    "        result_dataset[store_week_start].append(store_base_case)\n",
    "        result_dataset[store_week_start].append(int(row[case_idx.index('cases')]) - store_base_case)\n",
    "        store_base_case = int(row[case_idx.index('cases')])\n",
    "        store_week_start = cur_week_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dow Jones Industrial Average dataset\n",
    "\n",
    "We can see that the number data in the Dow Jones Industrial Average dataset contains commas. We need to remove that. Also, we will only take the \"Adjusted Close**\" column for each week's Dow Jones index. We are also computing the index difference for each week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_idx = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "store_week_start = None\n",
    "store_base_case = 0\n",
    "djifile.seek(0)\n",
    "for row in reader_dji:\n",
    "    if row[0] == 'Date':\n",
    "        continue\n",
    "    day_info = row[dji_idx.index('Date')]\n",
    "    day_info = day_info.split(' ')\n",
    "    if(len(day_info) != 3):\n",
    "        continue\n",
    "    cur_date = date(int(day_info[2]), month_idx.index(day_info[0]) + 1, int(day_info[1].split(',')[0]))\n",
    "    if cur_date < date(2020, 2, 17) or cur_date > date(2021, 1, 31):\n",
    "        continue\n",
    "    if store_week_start == None:\n",
    "        store_week_start = cur_date\n",
    "        store_base_case = float(row[dji_idx.index('Adj Close**')].replace(',',''))\n",
    "    if cur_date != store_week_start:\n",
    "        result_dataset[cur_date].append(float(row[dji_idx.index('Adj Close**')].replace(',','')))\n",
    "        result_dataset[cur_date].append(round(store_base_case - float(row[dji_idx.index('Adj Close**')].replace(',','')),2))\n",
    "        store_base_case = float(row[dji_idx.index('Adj Close**')].replace(',',''))\n",
    "        store_week_start = cur_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US Gasoline and Diesel Retail Prices dataset\n",
    "\n",
    "For this dataset, we are taking the values in the column named \"A1\", which stands for \"Weekly U.S. All Grades All Formulations Retail Gasoline Prices (Dollars per Gallon)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "gasolinefile.seek(0)\n",
    "for row in reader_gasoline:\n",
    "    if row[0] == 'Date':\n",
    "        continue\n",
    "    day_info = row[gasoline_idx.index('Date')]\n",
    "    day_info = day_info.split('/')\n",
    "    if(len(day_info) != 3):\n",
    "        continue\n",
    "    cur_date = date(int(day_info[2]), int(day_info[0]), int(day_info[1]))\n",
    "    if cur_date < date(2020, 2, 17) or cur_date > date(2021, 1, 24):\n",
    "        continue\n",
    "    cur_week_start = cur_date - timedelta(cur_date.weekday())\n",
    "    result_dataset[cur_week_start].append(float(row[gasoline_idx.index('A1')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly Unemployment Initial Claims dataset\n",
    "\n",
    "Nothing special about this dataset, just integrate into the result dataset according to date. (The date may not be a Monday, so need to adjust accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemploymentfile.seek(0)\n",
    "for row in reader_unemployment:\n",
    "    if row[0] == 'DATE':\n",
    "        continue\n",
    "    day_info = row[unemployment_idx.index('Adjusted Date')]\n",
    "    day_info = day_info.split('/')\n",
    "    if(len(day_info) != 3):\n",
    "        continue\n",
    "    cur_date = date(int(day_info[2]), int(day_info[0]), int(day_info[1]))\n",
    "    if cur_date < date(2020, 2, 17) or cur_date > date(2021, 1, 24):\n",
    "        continue\n",
    "    cur_week_start = cur_date - timedelta(cur_date.weekday())\n",
    "    result_dataset[cur_week_start].append(int(row[unemployment_idx.index('Initial Claims')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID-19 Mobility Trends Dataset\n",
    "Since our primary focus is the impact of the pandemic to US economy, we would like to remove COVID-19 mobility trends for other countries. We will take average for the mobility indices for each week. We are only taking the \"grocery and pharmacy\", \"residential\", \"retail and recreation\" indices for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilityfile.seek(0)\n",
    "cur_week_cumu = [0,0,0]\n",
    "for row in reader_mobility:\n",
    "    if row[0] == 'iso':\n",
    "        continue\n",
    "    if row[mobility_idx.index('iso')] != \"US\":\n",
    "        continue\n",
    "    day_info = row[mobility_idx.index('date')]\n",
    "    day_info = day_info.split('-')\n",
    "    if(len(day_info) != 3):\n",
    "        continue\n",
    "    cur_date = date(int(day_info[0]), int(day_info[1]), int(day_info[2]))\n",
    "    if cur_date < date(2020, 2, 17) or cur_date > date(2021, 1, 24):\n",
    "        continue\n",
    "    cur_week_cumu[0] += float(row[mobility_idx.index('grocery_and_pharmacy_percent_change_from_baseline')])\n",
    "    cur_week_cumu[1] += float(row[mobility_idx.index('residential_percent_change_from_baseline')])\n",
    "    cur_week_cumu[2] += float(row[mobility_idx.index('retail_and_recreation_percent_change_from_baseline')])\n",
    "    if cur_date.weekday() == 6:\n",
    "        cur_week_start = cur_date - timedelta(cur_date.weekday())\n",
    "        result_dataset[cur_week_start].append(round(cur_week_cumu[0] / 7,2))\n",
    "        result_dataset[cur_week_start].append(round(cur_week_cumu[1] / 7,2))\n",
    "        result_dataset[cur_week_start].append(round(cur_week_cumu[2] / 7,2))\n",
    "        cur_week_cumu = [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{datetime.date(2020, 2, 17): [25, 18, 28992.41, -3583.05, 2.518, 220000, 0.43, 0.71, 3.57], datetime.date(2020, 2, 24): [43, 61, 25409.36, 455.42, 2.555, 217000, 3.71, -0.71, 7.71], datetime.date(2020, 3, 2): [104, 644, 25864.78, -2679.16, 2.514, 211000, 6.71, -1.0, 8.43], datetime.date(2020, 3, 9): [748, 3759, 23185.62, -4011.64, 2.468, 282000, 14.57, 1.57, 1.86], datetime.date(2020, 3, 16): [4507, 38998, 19173.98, 2462.8, 2.343, 3307000, 5.71, 12.29, -27.71], datetime.date(2020, 3, 23): [43505, 120450, 21636.78, -584.25, 2.217, 6867000, -15.43, 17.57, -42.0], datetime.date(2020, 3, 30): [163955, 205102, 21052.53, 2666.84, 2.103, 6615000, -14.71, 18.57, -42.29], datetime.date(2020, 4, 6): [369057, 214961, 23719.37, 523.12, 2.022, 5237000, -16.71, 19.29, -45.71], datetime.date(2020, 4, 13): [584018, 200973, 24242.49, -467.22, 1.951, 4442000, -16.43, 18.43, -41.71], datetime.date(2020, 4, 20): [784991, 209202, 23775.27, -51.58, 1.91, 3867000, -14.43, 17.71, -39.71], datetime.date(2020, 4, 27): [994193, 193109, 23723.69, 607.63, 1.87, 3176000, -8.86, 14.86, -33.86], datetime.date(2020, 5, 4): [1187302, 167147, 24331.32, -645.9, 1.883, 2687000, -2.29, 14.43, -29.57], datetime.date(2020, 5, 11): [1354449, 161144, 23685.42, 779.74, 1.941, 2446000, -6.43, 14.0, -28.86], datetime.date(2020, 5, 18): [1515593, 154978, 24465.16, 917.95, 1.969, 2123000, -2.86, 12.43, -24.29], datetime.date(2020, 5, 25): [1670571, 150628, 25383.11, 1727.87, 2.049, 1897000, -3.86, 12.43, -23.14], datetime.date(2020, 6, 1): [1821199, 150442, 27110.98, -1505.44, 2.064, 1566000, -0.43, 10.43, -18.57], datetime.date(2020, 6, 8): [1971641, 154933, 25605.54, 265.92, 2.123, 1540000, -0.71, 9.29, -16.0], datetime.date(2020, 6, 15): [2126574, 198305, 25871.46, -855.91, 2.185, 1482000, 1.14, 8.29, -14.43], datetime.date(2020, 6, 22): [2324879, 280053, 25015.55, 811.81, 2.216, 1408000, -1.86, 8.86, -15.29], datetime.date(2020, 6, 29): [2604932, 353166, 25827.36, 247.94, 2.26, 1310000, 1.71, 9.0, -14.43], datetime.date(2020, 7, 6): [2958098, 421748, 26075.3, 596.65, 2.265, 1308000, -1.29, 8.86, -15.0], datetime.date(2020, 7, 13): [3379846, 465168, 26671.95, -202.06, 2.283, 1422000, -1.57, 8.71, -14.71], datetime.date(2020, 7, 20): [3845014, 458721, 26469.89, -41.57, 2.275, 1435000, -3.14, 8.71, -15.29], datetime.date(2020, 7, 27): [4303735, 423040, 26428.32, 1005.16, 2.265, 1191000, -2.57, 8.43, -14.43], datetime.date(2020, 8, 3): [4726775, 376836, 27433.48, 497.54, 2.266, 971000, -2.57, 8.0, -13.71], datetime.date(2020, 8, 10): [5103611, 351576, 27931.02, -0.69, 2.256, 1104000, -3.86, 7.86, -14.86], datetime.date(2020, 8, 17): [5455187, 299067, 27930.33, 723.54, 2.256, 1011000, -4.57, 7.71, -15.14], datetime.date(2020, 8, 24): [5754254, 291201, 28653.87, -520.56, 2.272, 884000, -5.71, 7.86, -15.71], datetime.date(2020, 8, 31): [6045455, 272410, 28133.31, -467.67, 2.311, 893000, -2.86, 6.57, -13.14], datetime.date(2020, 9, 7): [6317865, 257235, 27665.64, -8.22, 2.302, 866000, -6.14, 8.14, -16.14], datetime.date(2020, 9, 14): [6575100, 305799, 27657.42, -483.46, 2.274, 873000, -6.0, 6.71, -14.71], datetime.date(2020, 9, 21): [6880899, 296080, 27173.96, 508.85, 2.259, 849000, -6.57, 6.86, -15.43], datetime.date(2020, 9, 28): [7176979, 331007, 27682.81, 904.09, 2.259, 767000, -4.71, 6.57, -14.43], datetime.date(2020, 10, 5): [7507986, 355671, 28586.9, 19.41, 2.262, 842000, -5.43, 6.71, -15.43], datetime.date(2020, 10, 12): [7863657, 416146, 28606.31, -270.74, 2.257, 797000, -6.29, 7.43, -15.71], datetime.date(2020, 10, 19): [8279803, 498183, 28335.57, -1833.97, 2.24, 758000, -7.0, 7.43, -16.86], datetime.date(2020, 10, 26): [8777986, 599215, 26501.6, 1821.8, 2.234, 757000, -5.86, 7.86, -16.71], datetime.date(2020, 11, 2): [9377201, 814441, 28323.4, 1156.41, 2.204, 711000, -7.43, 7.86, -16.43], datetime.date(2020, 11, 9): [10191642, 1088552, 29479.81, -216.33, 2.188, 748000, -8.14, 9.14, -18.29], datetime.date(2020, 11, 16): [11280194, 1212834, 29263.48, 646.89, 2.202, 787000, -6.71, 9.14, -19.71], datetime.date(2020, 11, 23): [12493028, 1122711, 29910.37, 307.89, 2.194, 716000, -7.57, 12.43, -25.14], datetime.date(2020, 11, 30): [13615739, 1416694, 30218.26, -171.89, 2.211, 862000, -7.71, 9.71, -19.43], datetime.date(2020, 12, 7): [15032433, 1538182, 30046.37, 132.68, 2.246, 892000, -7.57, 9.71, -20.14], datetime.date(2020, 12, 14): [16570615, 1513141, 30179.05, 20.82, 2.247, 806000, -5.43, 10.29, -19.0], datetime.date(2020, 12, 21): [18083756, 1281984, 30199.87, 406.61, 2.311, 782000, -4.71, 12.71, -23.86], datetime.date(2020, 12, 28): [19365740, 1553721, 30606.48, 491.49, 2.33, 784000, -8.86, 14.29, -22.29], datetime.date(2021, 1, 4): [20919461, 1755424, 31097.97, -283.71, 2.336, 927000, -10.14, 11.14, -22.86], datetime.date(2021, 1, 11): [22674885, 1452397, 30814.26, 182.72, 2.403, 875000, -12.86, 10.57, -24.71], datetime.date(2021, 1, 18): [24127282, 1207130, 30996.98, -1014.36, 2.464, 812000, -13.86, 10.86, -25.57]}\n"
     ]
    }
   ],
   "source": [
    "print(result_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Outputing the integrated dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close all the input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilityfile.close()\n",
    "casefile.close()\n",
    "djifile.close()\n",
    "unemploymentfile.close()\n",
    "gasolinefile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output our integrated dataset to a new file called \"covid_analysis.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('covid_analysis.csv', 'w', newline='') as csvfile:\n",
    "    covidwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='\"')\n",
    "    covidwriter.writerow(['Start Date', 'Cases at Start', 'Case Increase', 'Dow Jones Adjusted Close', 'Dow Jones Difference', 'Gasoline Price', 'Unemployment Initial Claims', 'Grocery and Pharmacy Mobility', 'Residential Mobility', 'Retail and Recreation Mobility'])\n",
    "    for item in result_dataset.items():\n",
    "        result = item[1] \n",
    "        result.insert(0, item[0].isoformat())\n",
    "        covidwriter.writerow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our data cleaning, wrangling and integration for this part of analysis. Here is the result of this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date, Cases at Start, Case Increase, Dow Jones Adjusted Close, Dow Jones Difference, Gasoline Price, Unemployment Initial Claims, Grocery and Pharmacy Mobility, Residential Mobility, Retail and Recreation Mobility\n",
      "2020-02-17, 25, 18, 28992.41, -3583.05, 2.518, 220000, 0.43, 0.71, 3.57\n",
      "2020-02-24, 43, 61, 25409.36, 455.42, 2.555, 217000, 3.71, -0.71, 7.71\n",
      "2020-03-02, 104, 644, 25864.78, -2679.16, 2.514, 211000, 6.71, -1.0, 8.43\n",
      "2020-03-09, 748, 3759, 23185.62, -4011.64, 2.468, 282000, 14.57, 1.57, 1.86\n",
      "2020-03-16, 4507, 38998, 19173.98, 2462.8, 2.343, 3307000, 5.71, 12.29, -27.71\n",
      "2020-03-23, 43505, 120450, 21636.78, -584.25, 2.217, 6867000, -15.43, 17.57, -42.0\n",
      "2020-03-30, 163955, 205102, 21052.53, 2666.84, 2.103, 6615000, -14.71, 18.57, -42.29\n",
      "2020-04-06, 369057, 214961, 23719.37, 523.12, 2.022, 5237000, -16.71, 19.29, -45.71\n",
      "2020-04-13, 584018, 200973, 24242.49, -467.22, 1.951, 4442000, -16.43, 18.43, -41.71\n",
      "2020-04-20, 784991, 209202, 23775.27, -51.58, 1.91, 3867000, -14.43, 17.71, -39.71\n"
     ]
    }
   ],
   "source": [
    "with open('covid_analysis.csv', newline='') as covidanalysisfile:\n",
    "    reader_analysis = csv.reader(covidanalysisfile, delimiter=',')\n",
    "    count = 0\n",
    "    for row in reader_analysis:\n",
    "        if count > 10:\n",
    "            break\n",
    "        count = count + 1\n",
    "        print(', '.join(row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
